trainer:
  lr: 1e-5
  optimizer: 'AdamW'
  lr_scheduler: 'ReduceLROnPlateau'

dataset:
  batch_size: 452
  dataloader_num_workers: 8,
  dataset_path: './'


model:
  num_classes: 10

vit:
  embed_dim: 256
  hidden_dim: 512
  num_heads: 8
  num_layers: 6
  num_channels: 3
  patch_size: 4
  num_patches: 64
  dropout: 0.2

mlp:
  image_size: 256
  channels: 3
  patch_size: 16
  dim: 512
  depth: 12